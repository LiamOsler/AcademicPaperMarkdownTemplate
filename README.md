### Project Paper Summary (individual)
###### Wednesday, September 28, 2022

<hr>

#### Personal Information:

**Name:**<br>Liam Osler 

**Project Team:**<br>Fuschia (camera app with special effects photo editing)

<hr>

#### Paper Information:

**Title:**<br>WUW - wear Ur world: a wearable gestural interface

**Authors:**<br>Pranav Mistry, Prattie Maes, Liyan Chang

**Citation:**<br> Mistry, Maes, P., & Chang, L. (2009). **WUW - wear Ur world: a wearable gestural interface.** *CHI  ’09 Extended Abstracts on Human Factors in Computing Systems*, 4111–4116. https://doi.org/10.1145/1520340.1520626

<hr>

#### Paper Review:
##### Background:
In this paper, the authors discuss and explore modes of interaction with wearable technology using gestural actions informed through live projected feedback.

The authors of the paper envision applications for technologically enhanced reality with the use of wearable technology. In their experiments, that technology takes the form of head-mounted camera and head-mounted projector.

Similarities between the paper and the groups' research topics include wearable technologies featuring camera sensors and how to design user interfaces for devices of this nature. The paper discusses photo taking and editing applications and how a gesture based interface could be used to supplement them.

##### Study Methods:
The authors of the paper created a wearable system consisting of a head-mounted camera, a head-mounted projector and a Windows based laptop. On that laptop a program written in C# performed image analysis on the camera's video feed to perform hand-tracking. This hand-tracking was used to perform gesture recognition. The projector could be used to provide visual feedback of the application state and to supply information to the user about their surroundings. This information is projected on to their surroundings, or the body of the user themselves.

The paper does not detail if any experiments were conducted where the subjects were not the authors. The paper does not detail any experimental methods that could be used to quantify the usefulness or gains in efficiency created by the interface.

##### Results:

The authors found that there are interesting and potentially useful applications of wearable technologies and gesture based interfaces. 

The authors demonstrate methods of interacting with digital design and content creation software through the use of these interfaces.

The authors speculate on novel ways which a combination of camera sensor equipped wearable technologies could be used to create interactive entertainment and educational experiences, enhance productivity in the workplace and to improve efficiency of interaction with human-computer interfaces.

##### Recommendations:
In the discussions and future work segment of the paper, the authors discuss how they can build more of their wearable systems. Based on their reflections, it seems like the fragility of their prototyped systems limits the possibility for larger-scale mass tests to be conducted with them. At the time of the writing of the paper (2009) wearable technologies like smartwatches were not prolific, so the use of a commercially available device with the required sensing and a processing capabilities wouldn't have been possible.

##### Connections:
The authors haven't considered the use of a wrist-wearable sensor-enhanced technology like smartwatch in their paper. Their approach to gesture recognition is based on object-recognition through image processing. This gesture recognition therefore requires the user's hand to be in the viewport of the camera. Wearable technologies like smartwatches are nowadays often equipped with accelerometers which can accurately track movement. This tracking can be performed regardless of where the user's hand happens to be in relation to a camera.

There have been some limited attempts to combine the smartwatch with a projector. While no commercially available unit exists, there have been prototypes shown in 2018 and 2020. These demonstrations show the use of gesture enhanced interfaces combined with enhanced reality through the use of projector technologies. In the case of both technology demonstrators, this involved projection on to the wrist or hand of the user near where the smartwatch is banded.
